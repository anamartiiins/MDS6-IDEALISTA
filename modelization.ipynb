{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from src.evaluation.evaluation import calculate_metrics, export_model, save_graph_feature_importance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import tree, ensemble\n",
    "import xgboost\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "from src.modelization.models_utils import get_pipeline\n",
    "from src.constants import BASE_PATH_EXPERIMENTS, PATH_EVALUATION_DF_WITH_METRICS_CSV, PATH_EVALUATION_CSV, PATH_TRAIN, PATH_TEST\n",
    "from datetime import datetime\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "import warnings\n",
    "import zipfile\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Data\n",
    "df_train = pd.read_csv(PATH_TRAIN)\n",
    "df_test = pd.read_csv(PATH_TEST)\n",
    "if  os.path.exists(PATH_EVALUATION_DF_WITH_METRICS_CSV):\n",
    "    evaluation_df_with_metrics = pd.read_csv(PATH_EVALUATION_DF_WITH_METRICS_CSV)\n",
    "if  os.path.exists(PATH_EVALUATION_CSV):\n",
    "    evaluation = pd.read_csv(PATH_EVALUATION_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop=['geometry', 'barrio_id', 'barrio']\n",
    "df_train = df_train.drop(columns=columns_to_drop)\n",
    "df_test = df_test.drop(columns=columns_to_drop)\n",
    "\n",
    "# Evaluate with different targets: precio, precio_unitario_m2, precio_logaritmico\n",
    "target = \"precio_unitario_m2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = 'Precio medio por barrio - precio unitario'\n",
    "if target == 'precio':\n",
    "    metrics_df, df_test_with_metrics = calculate_metrics(df_test['precio'], df_test['precio_mean_barrio'], df_test, model_name=baseline_model)\n",
    "else:\n",
    "    metrics_df, df_test_with_metrics = calculate_metrics(df_test['precio_unitario_m2'], df_test['precio_unitario_m2_mean_barrio'], df_test, model_name=baseline_model)\n",
    "\n",
    "df_test_with_metrics['model_name'] = baseline_model\n",
    "\n",
    "if not os.path.exists(PATH_EVALUATION_DF_WITH_METRICS_CSV):\n",
    "    evaluation_df_with_metrics=pd.DataFrame()\n",
    "    evaluation_df_with_metrics = pd.concat([evaluation_df_with_metrics, df_test_with_metrics], ignore_index=True)\n",
    "    evaluation_df_with_metrics.to_csv(PATH_EVALUATION_DF_WITH_METRICS_CSV, index=False)\n",
    "\n",
    "if not os.path.exists(PATH_EVALUATION_CSV):\n",
    "    evaluation=pd.DataFrame()\n",
    "    evaluation =pd.concat([evaluation, metrics_df], ignore_index=True)\n",
    "    evaluation.to_csv(PATH_EVALUATION_CSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['precio', 'precio_unitario_m2', \"precio_logaritmico\"])\n",
    "y_train = df_train[target]\n",
    "X_test = df_test.drop(columns=['precio', 'precio_unitario_m2', \"precio_logaritmico\"])\n",
    "y_test = df_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt = tree.DecisionTreeRegressor()\n",
    "model_rf = ensemble.RandomForestRegressor()\n",
    "model_gb = ensemble.GradientBoostingRegressor()\n",
    "model_xgb = xgboost.XGBRegressor()\n",
    "\n",
    "#To use CatBoost is needed to transform data into a Pool Object\n",
    "train_dataset = cb.Pool(X_train, y_train) \n",
    "test_dataset = cb.Pool(X_test, y_test)\n",
    "model_cb = cb.CatBoostRegressor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_test = {\n",
    "                  f'Decision Tree wo CV {target}' : model_dt, \n",
    "                  f'RandomForest wo CV {target}' : model_rf, \n",
    "                  f'Gradient Boosting wo CV {target}': model_gb, \n",
    "                  f'eXtreme Gradient Boost wo CV {target}':model_xgb,\n",
    "                  f'CatBoost wo CV {target}': model_cb\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models_to_test.items():\n",
    "    # Create pipeline\n",
    "    pipeline = get_pipeline(\n",
    "        base_model=model,\n",
    "        impute=True,  \n",
    "        scale=True,  \n",
    "        encode=True,\n",
    "        num_features=X_train.columns.to_list()\n",
    "    )\n",
    "        \n",
    "    # Fit the pipeline and make predictions\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    #Export Model\n",
    "    output_folder = export_model(\n",
    "    model=model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    base_path=BASE_PATH_EXPERIMENTS,\n",
    "    save_model=True,     \n",
    "    save_datasets=True,  \n",
    "    zip_files=True      \n",
    "    )\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics_df, df_test_with_metrics = calculate_metrics(y_test, y_pred, df_test, model_name)\n",
    "\n",
    "    # Add model_name column to df_test_with_metrics\n",
    "    df_test_with_metrics['model_name'] = model_name\n",
    "    df_test_with_metrics['model_folder'] = f\"experiment_{model_name}_{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "\n",
    "    # Append df_test_with_metrics to all_df_test_with_metrics\n",
    "    evaluation_df_with_metrics = pd.concat([evaluation_df_with_metrics, df_test_with_metrics], ignore_index=True)\n",
    "\n",
    "    # Append metrics_df to all_metrics_df\n",
    "    evaluation =pd.concat([evaluation, metrics_df], ignore_index=True)\n",
    "    \n",
    "# Save the DataFrames to CSV files\n",
    "evaluation.to_csv(PATH_EVALUATION_CSV, index=False)\n",
    "evaluation_df_with_metrics.to_csv(PATH_EVALUATION_DF_WITH_METRICS_CSV, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor (model_dt):\n",
    "# max_depth: Typically ranges from 1 to 32.\n",
    "# min_samples_split: Typically ranges from 2 to 20.\n",
    "# min_samples_leaf: Typically ranges from 1 to 10.\n",
    "# max_features: Typically ranges from 1 to the number of features.\n",
    "\n",
    "params_dt = {\"max_depth\": [5, 10, 15], \n",
    "             \"min_samples_split\" : [4, 6, 10 ],\n",
    "             \"max_features\": [15,20]\n",
    "             }\n",
    "\n",
    "# Random Forest Regressor (model_rf):\n",
    "# n_estimators: Typically ranges from 50 to 1000.\n",
    "# max_depth: Typically ranges from 1 to 32.\n",
    "# min_samples_split: Typically ranges from 2 to 20.\n",
    "# min_samples_leaf: Typically ranges from 1 to 10.\n",
    "\n",
    "params_rf = {'n_estimators': [75, 200, 500] ,\n",
    "          'max_depth' : [5,10] ,\n",
    "          'min_samples_split' : [4, 6, 8],\n",
    "          }\n",
    "\n",
    "\n",
    "# Gradient Boosting Regressor (model_gb):\n",
    "# n_estimators: Typically ranges from 50 to 1000.\n",
    "# learning_rate: Typically ranges from 0.01 to 0.1.\n",
    "# max_depth: Typically ranges from 1 to 10.\n",
    "# min_samples_split: Typically ranges from 2 to 20.\n",
    "\n",
    "params_gb = {'n_estimators':[75, 150, 200, 500],\n",
    "             'learning_rate' : [0.05, 0.1, 0.15],\n",
    "             'max_depth' : [5, 10, 15],\n",
    "             'min_samples_split' : [4, 6, 8],\n",
    "             }\n",
    "\n",
    "# XGBoost Regressor (model_xgb):\n",
    "# n_estimators: Typically ranges from 50 to 1000.\n",
    "# learning_rate: Typically ranges from 0.01 to 0.1.\n",
    "# max_depth: Typically ranges from 1 to 10.\n",
    "# min_child_weight: Typically ranges from 1 to 10.\n",
    "\n",
    "params_xgb = {'n_estimators': [75, 150, 200, 500],\n",
    "              'learning_rate' : [0.05, 0.1, 0.15],\n",
    "              'max_depth' : [5, 10, 15],\n",
    "              'min_child_weight' : [2,3,5]}\n",
    "\n",
    "# CatBoost Regressor (model_cb):\n",
    "# n_estimators: Typically ranges from 50 to 1000.\n",
    "# learning_rate: Typically ranges from 0.01 to 0.1.\n",
    "# max_depth: Typically ranges from 1 to 10.\n",
    "# l2_leaf_reg: Typically ranges from 1 to 10.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform grid search and save results\n",
    "folder_names_params = {\n",
    "    'experiment_DecisionTreeRegressor_20240303-151554': params_dt,\n",
    "    'experiment_RandomForestRegressor_20240303-151806': params_rf,\n",
    "    'experiment_GradientBoostingRegressor_20240303-151845': params_gb,\n",
    "    'experiment_XGBRegressor_20240303-151849': params_xgb,\n",
    "}\n",
    "\n",
    "for folder, param_grid in folder_names_params.items():\n",
    "    # Path to the zip file\n",
    "    zip_file_path = f'src/evaluation/{folder}/model.zip'\n",
    "    \n",
    "    # Name of the file within the zip folder\n",
    "    file_name_within_zip = 'model.pkl'\n",
    "\n",
    "    # Open the zip file\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        # Extract the file from the zip folder\n",
    "        with zip_ref.open(file_name_within_zip) as file:\n",
    "            # Read the file using pandas\n",
    "            pipeline = pickle.load(file)\n",
    "    \n",
    "    # Grid search for best parameters\n",
    "    gs = GridSearchCV(estimator=pipeline,\n",
    "                      param_grid=param_grid,\n",
    "                      scoring='neg_root_mean_squared_error',\n",
    "                    #   CV=5\n",
    "                      )\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    # Store the grid search results for the current model and folder\n",
    "    grid_search_info = {\n",
    "        'best_params': gs.best_params_,\n",
    "        'best_score': gs.best_score_,\n",
    "        'cv_results': gs.cv_results_,\n",
    "    }\n",
    "\n",
    "    # Save the grid search information to a JSON file within the folder\n",
    "    grid_search_output_file = os.path.join(f'src/evaluation/{folder}', 'grid_search_info.json')\n",
    "    with open(grid_search_output_file, 'w') as f:\n",
    "        json.dump(grid_search_info, f)\n",
    "\n",
    "    # Save in the model folder the graph with feature importance\n",
    "    save_graph_feature_importance(model=model, X_train=X_train, folder=folder)\n",
    "\n",
    "print(\"Grid search information saved successfully. Feature Importance graph saved successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
